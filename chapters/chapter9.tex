\chapter{无监督语言学习}{Unsupervised Language Learning}
前文所述的语言架构，并未针对系统许多部分使用的多种规则来源提出任何内蕴假设。所有这些规则都可被建模为超图的转换，但这些规则从哪而来？在目前的实行之中，这些规则都是手动撰写，但这并不是系统的必要层面。我们当前研究的重点之一，是以非监督式语料分析来取代手编分析规则。本章节扼要论述我们目前关于这点的研究方向。 

以自动化、非监督式语料库为基础的语法学习，成为计算语言学界的「圣杯」之一已有些时日[?]。我们已完成了几项有趣的研究，但平心而论，在这方面尚无十分显著的进展。

我们将本方法描述为以「深度学习」为导向的非监督式语法学习，因为此方法是基于语料的分层模式识别：在允许「较高层级」（较抽象）模式回授给的阶层系统中识别模式、再识别这些模式中的模式等，以回授给该阶层，并影响较低层级的识别。本方法并不采取如玻尔兹曼机 (Deep Boltzmann) 或递归神经网络等传统的深度学习架构。在概念上，本方法是基于与这些运算法相同的直觉性，之中依赖其输入数据中所存在的分层结构，并利用带有大量反馈的分层模式识别结构，自适应地识别出此分层结构。但我们使用的特定模式识别算法以及构建的特定阶层性质，都是遵循计算语言学（基于统计和法则两者）中起作用和无效的既有知识。 

虽本文提出的整体方法堪称新颖，但多数细部理念均为众多作者先前研究成果的延伸和概括，尔后将提及、并包括在以下论述的一些个案中。我们认为，使大型语料库的非监督式语言学习成为可能之需求，此具体构想在过去十年以来已逐渐崭露头角。本论文提出的方法具有一些独特性，但也有许多层面是其他学者已验证过的。

2.1 假设的语言基础结构
虽然本章节概述的方法旨在从文本数据学习某语言的语言内容，但目标并不在于学习语言的观念。我们含蓄地假设，某模型中的学习系统始于基本的「语言基础结构」，其显示了某自然语言的多个成分，以及这些成分一般是如何相互关联；而此模型学习了某语言特有的语言内涵。原则上，要使人工智能系统学习某语言的基本概念和构建其本身的语言基础结构，也是有可能的。然而这并不是我们要在此阐述的问题；我们臆测此等方法会需要用上大幅更多的计算资源。 

此处假设的语言基础架构包括本论文上一章节所探讨的关键要素：
	假设表达语法（从属）规则的形式体系，例如链语法 
	从语句中摘取句法结构的分析器，例如链语法分析器
	假设表达语义关系的形式体系，例如用于 RelEx2Logic 输出程序的 PLN 形式体系

2.2 待学习的语言内涵
以上述语言基础结构为前提，语言学习系统待学习的是某语言特有的语言内涵。 
具体而言，以假设之结构为前提，系统要学习的重要事物包括：
	语法形式体系的细微之处。例如在链语法语境中，系统必须学会用来形成「外加语」的一系列「链类型」。 
	必须学会不同单词的词汇分录。 
	必须学会语义关系。 
	必须学会习语和短语。

2.3 由大型语料库的无监督式语言学习法

过去数十年以来由许多作者发表的研究中，已论证上列的多个项目在非监督式的设置中可如何被学习（欲了解相关背景，请见[?, ?, ?, ?, ?, ?, ?]的例子）。然而所有先前论证的结果，都是通过假设周围基础结构预先就存在的研究中个别得到的，其远超过我们以上所做的假设。在此提出的方法可被解读为这些技术的结合、概括和精炼化，此方法为创造大体上可从大型语料库开始学习的系统，最终成果为构建出有效、有用的自然语言理解系统。

这之所以可行，是因为我们结合的不同先前方法有深度的算法通用性，由于上述研究报告中使用的不同的强调重点和技术词汇，在以往文献中向来不是很明显。所有以上提到的先前研究都援引最大熵值原则的某些或其他变异，有时明确，但通常是含蓄的。一般而言，最大熵值原则为（隐式）马尔可夫模型、马尔可夫网络和霍普菲尔德神经网络等学习系统提供了基础，而这些系统间接地连接了基于贝叶斯概率的分析。然而，熵值最大化的实际任务是个非定常多項式困难问题 (NP-hard problem)；向前的进展会视捷径算法、近似算法和机智算法而定，其中部分是出于一般性质，而有些则是出于领域相依性。

2.4 无监督语言学习的统一方法
在抽象的概念层面上，在此提出的方法将语言学习描述为一般的学习环路：
1. 将显示相似使用模式（系统检查被赋予可紧密记述的后设语言使用模式）的语言实体（例如字词或语言关系，如前一节所述）聚集在一起。许多、但未必所有被给予的语言实体使用模式，会涉及配合其他语言实体的使用。 
2. 针对每个此等编组做分类标签。 
3. 将这些分类标签添加到系统的后设语言。
4. 回到第一步。
这种学习环路的成果若成功，这会是具备以下的分层构成聚集语言关系
语言连贯性质：从与其他语言主体间的关系可观察到的紧密记述模式来看，语言主体有合理程度上良好的可表征性。
在这种语言连贯性中，并没有任何是本质上具有「深度」或有层次的。然而，通过上述的递归分层学习环路学习与其他语言主体相关模式的能力，会视研究的语言数据中存在的显著分层结构而定。诸多证据表明此等分层结构确实存在于自然语言。本方法中的「深度学习」通过上述的环路深植于重复循环 – 每一次完成了环路，学习的层级就会更深。
此泛用的学习程序为以符号表现之一般程序的特殊案例，在[?]和其他地方，此程序被描述为一般智能的关键层面。在此程序中，系统会在本身和其环境找出模式，再将这些模式通过简单记号、或以成为系统原有知识表示法一部分的符号（以及其对自己描述事物的部分「后设语言」）来表现。将复杂的模式呈现为简单的象征符号，就可轻易地检查涉及此模式成分的其他模式。
如上所述的一般形式，值得注意的是「语言学习环路」并非局限于语料库为基础的分析，而是也包含了使用模式语言之外的层面，比如手势、语调、语言沟通的物理语境和社会语境等。结合语言和非语言因素，即构成了「使用模式」。然而，语料的限制未必剥夺语言学习环路的强度；而纯粹是限制了使用模式的特定级别，信息含量必须靠经验决定。
原则上，仅根据上述学习环路泛用的失信过程来创造机能性的语言学习系统， 是有可能的。然而实际上，对于使用模式特定种类的偏差，在引导语言学习上会很有价值。在计算语言学习情境中，值得将语言学习程序分解为多个基本语言学习环路的例子，每个例子侧重于不同使用模式，并以特定方式与彼此结合。事实上，这就是我们将在此提出的。
具体而言，在此提出的语言学习程序牵涉到：
	纯学习句法语言关系（例如前述的链类型和词汇分录）的语言学习环路，这些语言关系接着会提供给对句法分析器。 
	学习较高级别的「句法语义」语言关系（例如前述的语义关系、习语、词汇功能语法）的语言学习环路，这些语言关系会从句法分析器所输出的内容摘取。
这两种环路并非彼此独立；第二种环路可反馈有关所摘取结构的正确性给第一种环路；当第一种环路产生更精准、确信的结果，第二种环路可转而对其所输出更加确信。从这个角度来看，两种环路打击了「深度学习」在神经网络训练应付的同种慢收敛问题。
在此情境的句法分析器，是用来从相关某句子的句法关系图中摘取有向无环图，通常为树状。这些有向无环图代表句子的语法分析。因此在此提出的学习程序整体范畴，在于学习一种句法关系的系统；此系统显示适当的连贯性，并在被传入适切的分析器时生成语法分析树，造就显示适当连贯性的句法语义关系系统。
当然，我们在此论述的方法仅为高标准。我们具体详细说明了实例化上述观念的演算法，并正在实行软件中的演算法；欲进一步获得信息，请参考[?]。


2.5 增量学习的重要性
此处所述的学习程序，是由较单纯的句法和语义逐步形成复杂的句法和语义。最初所需的是源自语料库的基本前后关系。以适当的句法和语义形式体系、以及语义引导的语法分析器作为前提，其他的一切则由此逐步建立。
为让此自举法 (Bootstrapping) 学习运作得当，一般会需要从简单的语言开始，以免让文本内含的语义关系与简答的前、后关系之间相差甚远。文本的复杂性会逐渐加强。举例来说，按照增加的阅读水平来对极大型的语料库去做排序，即可达到所需的效果。我们当前的研究方向牵涉到增建此述的算法具体实例，目标是以增量学习的方式将演算法运用于维基百科的语料库。
